{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing started!\n",
      "preprocessing complete!\n",
      "[47, 24, 13, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0.0, 0.0, 0, 443, 0, 0, 1, 3, 0, 1, 0, '', 0, 0, 47, 7, 3, 7, 5.25, 0, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "from urllib.parse import urlparse\n",
    "import socket\n",
    "import tldextract\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def random_domain(url):\n",
    "    hostname = urlparse(url).hostname or \"\"\n",
    "    return 1 if re.match(r'^[a-zA-Z0-9]{7,}$', hostname.split('.')[0]) else 0\n",
    "\n",
    "def shortening_service(url):\n",
    "    shorteners = [\"bit.ly\", \"t.co\", \"goo.gl\", \"tinyurl.com\", \"is.gd\", \"ow.ly\"]\n",
    "    return 1 if any(service in url for service in shorteners) else 0\n",
    "\n",
    "def path_extension(url):\n",
    "    path = urlparse(url).path\n",
    "    return path.split(\".\")[-1] if \".\" in path else \"\"\n",
    "\n",
    "def nb_redirection(url):\n",
    "    return url.count(\"//\") - 1\n",
    "\n",
    "def length_words_raw(url):\n",
    "    return len(url)\n",
    "\n",
    "\n",
    "def char_repeat(url):\n",
    "    return max(Counter(url).values())\n",
    "\n",
    "def word_lengths(hostname):\n",
    "    words = hostname.replace(\"-\", \" \").split(\".\")\n",
    "    if not words:\n",
    "        return 0, 0, 0\n",
    "    return min(map(len, words)), max(map(len, words)), sum(map(len, words)) / len(words)\n",
    "\n",
    "def extract_word_features(url):\n",
    "    hostname = urlparse(url).hostname or \"\"\n",
    "    return word_lengths(hostname)\n",
    "\n",
    "def phish_hints(url):\n",
    "    suspicious_words = [\"secure\", \"account\", \"bank\", \"login\", \"verify\", \"update\"]\n",
    "    return 1 if any(word in url.lower() for word in suspicious_words) else 0\n",
    "\n",
    "known_brands = [\"paypal\", \"google\", \"facebook\", \"bank\"]\n",
    "\n",
    "def brand_in_domain(url):\n",
    "    domain = tldextract.extract(url).domain\n",
    "    return 1 if any(brand in domain.lower() for brand in known_brands) else 0\n",
    "\n",
    "def brand_in_subdomain(url):\n",
    "    subdomain = tldextract.extract(url).subdomain\n",
    "    return 1 if any(brand in subdomain.lower() for brand in known_brands) else 0\n",
    "\n",
    "def brand_in_path(url):\n",
    "    path = urlparse(url).path\n",
    "    return 1 if any(brand in path.lower() for brand in known_brands) else 0\n",
    "\n",
    "import whois\n",
    "\n",
    "def domain_registration_length(url):\n",
    "    try:\n",
    "        domain_info = whois.whois(urlparse(url).hostname)\n",
    "        expiration_date = domain_info.expiration_date\n",
    "        creation_date = domain_info.creation_date\n",
    "        if isinstance(expiration_date, list):\n",
    "            expiration_date = expiration_date[0]\n",
    "        if isinstance(creation_date, list):\n",
    "            creation_date = creation_date[0]\n",
    "        return (expiration_date - creation_date).days if expiration_date and creation_date else 0\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "def domain_age(url):\n",
    "    try:\n",
    "        domain_info = whois.whois(urlparse(url).hostname)\n",
    "        creation_date = domain_info.creation_date\n",
    "        if isinstance(creation_date, list):\n",
    "            creation_date = creation_date[0]\n",
    "        return (datetime.now() - creation_date).days if creation_date else 0\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "import requests\n",
    "\n",
    "def web_traffic(url):\n",
    "    try:\n",
    "        domain = urlparse(url).hostname\n",
    "        alexa_url = f\"https://data.alexa.com/data?cli=10&dat=s&url={domain}\"\n",
    "        response = requests.get(alexa_url)\n",
    "        if \"<POPULARITY URL=\" in response.text:\n",
    "            rank = response.text.split(\"<POPULARITY URL=\")[1].split(\"TEXT=\")[1].split(\"/>\")[0]\n",
    "            return int(rank)\n",
    "    except:\n",
    "        return -1\n",
    "\n",
    "def google_index(url):\n",
    "    try:\n",
    "        query = f\"site:{urlparse(url).hostname}\"\n",
    "        response = requests.get(f\"https://www.google.com/search?q={query}\")\n",
    "        return 1 if \"did not match any documents\" not in response.text else 0\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def page_rank(url):\n",
    "    try:\n",
    "        rank_api = f\"https://api.example.com/pagerank?domain={urlparse(url).hostname}\"\n",
    "        response = requests.get(rank_api)\n",
    "        return int(response.text) if response.status_code == 200 else 0\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def http_in_path(url):\n",
    "    path = urlparse(url).path\n",
    "    return 1 if \"http\" in path else 0\n",
    "\n",
    "def https_token(url):\n",
    "    path = urlparse(url).path\n",
    "    return 1 if \"https\" in path else 0\n",
    "\n",
    "def ratio_digits_url(url):\n",
    "    return sum(c.isdigit() for c in url) / len(url)\n",
    "\n",
    "def ratio_digits_host(url):\n",
    "    hostname = urlparse(url).hostname\n",
    "    return sum(c.isdigit() for c in hostname) / len(hostname) if hostname else 0\n",
    "\n",
    "def punycode(url):\n",
    "    hostname = urlparse(url).hostname\n",
    "    return 1 if hostname and \"xn--\" in hostname else 0\n",
    "\n",
    "def port(url):\n",
    "    parsed_url = urlparse(url)\n",
    "    return parsed_url.port if parsed_url.port else (-1 if parsed_url.scheme == \"http\" else 443)\n",
    "\n",
    "def tld_in_path(url):\n",
    "    tld = tldextract.extract(url).suffix\n",
    "    return 1 if tld in urlparse(url).path else 0\n",
    "\n",
    "def tld_in_subdomain(url):\n",
    "    extracted = tldextract.extract(url)\n",
    "    return 1 if extracted.suffix in extracted.subdomain else 0\n",
    "\n",
    "def abnormal_subdomain(url):\n",
    "    return 1 if urlparse(url).hostname.count('.') > 2 else 0\n",
    "\n",
    "def nb_subdomains(url):\n",
    "    return urlparse(url).hostname.count('.')\n",
    "\n",
    "def prefix_suffix(url):\n",
    "    return 1 if \"-\" in urlparse(url).hostname else 0\n",
    "\n",
    "def url_preprocessing(url):\n",
    "    parameters = []\n",
    "    print(\"preprocessing started!\")\n",
    "    parameters.append(len(url)) #url\n",
    "    parameters.append(len(urlparse(url).hostname)) #hostname\n",
    "    parameters.append(len(socket.gethostbyname(urlparse(url).hostname))) #ip\n",
    "    parameters.append(url.count('.')) #dots\n",
    "    parameters.append(url.count('-')) #hyphens\n",
    "    parameters.append(url.count('@')) #@\n",
    "    parameters.append(url.count('?')) #?\n",
    "    parameters.append(url.count('&')) #&\n",
    "    parameters.append(url.count('|')) #pipeline\n",
    "    parameters.append(url.count('=')) #eq\n",
    "    parameters.append(url.count('_')) #underscore\n",
    "    parameters.append(url.count('~')) #tilde\n",
    "    parameters.append(url.count('%')) #percentage\n",
    "    parameters.append(url.count('/')) #slash\n",
    "    parameters.append(url.count('*')) #star\n",
    "    parameters.append(url.count(':'))    \n",
    "    parameters.append(url.count(','))\n",
    "    parameters.append(url.count(';'))\n",
    "    parameters.append(url.count('$'))\n",
    "    parameters.append(url.count(' '))\n",
    "    parameters.append(url.count('www'))\n",
    "    parameters.append(url.count('com'))\n",
    "    parameters.append(url.count('//'))   \n",
    "    parameters.append(http_in_path(url))\n",
    "    parameters.append(https_token(url))\n",
    "    parameters.append(ratio_digits_url(url))\n",
    "    parameters.append(ratio_digits_host(url))\n",
    "    parameters.append(punycode(url))\n",
    "    parameters.append(port(url))\n",
    "    parameters.append(tld_in_path(url))\n",
    "    parameters.append(tld_in_subdomain(url))\n",
    "    parameters.append(abnormal_subdomain(url))\n",
    "    parameters.append(nb_subdomains(url))\n",
    "    parameters.append(prefix_suffix(url))\n",
    "    parameters.append(random_domain(url))\n",
    "    parameters.append(shortening_service(url))\n",
    "    parameters.append(path_extension(url))\n",
    "    parameters.append(nb_redirection(url))\n",
    "    parameters.append(nb_redirection(url))\n",
    "    parameters.append(length_words_raw(url))\n",
    "    parameters.append(char_repeat(url))\n",
    "    shortest_word_host, longest_word_host, avg_word_host = extract_word_features(url)\n",
    "    parameters.append(shortest_word_host)\n",
    "    parameters.append(longest_word_host)\n",
    "    parameters.append(avg_word_host)\n",
    "    # check once again\n",
    "    parameters.append(phish_hints(url))\n",
    "    parameters.append(brand_in_domain(url))\n",
    "    parameters.append(brand_in_subdomain(url))\n",
    "    parameters.append(brand_in_path(url))\n",
    "\n",
    "    return parameters\n",
    "\n",
    "print(url_preprocessing(\"https://console.cloud.google.com/apis/dashboard\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phishing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shaur\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "rf_model = joblib.load('phishing_detector.pkl')\n",
    "\n",
    "# parameters = [33,26,0,2,0,0,0,0,0,0,0,0,0,2,0,1,0,0,0,0,0,0,0,0,1,0.03030303,0.038461538,0,0,0,0,0,2,0,0,1,0,1,0,2,0,8,8,0,13,13,0,10.5,10.5,0.0,0,1,0,0,0,0,10,0.1,0.9,0,0,0,0.7777777779999999,0,0.5555555560000001,0,1,0.0,0,0.0,0.0,0,0,0,33.33333333,0,0,0,1,0,0,374,7295,0,0,1,5]\n",
    "parameters = []\n",
    "\n",
    "parameters = np.array(parameters).reshape(1, -1)\n",
    "\n",
    "y_pred = rf_model.predict(parameters)\n",
    "\n",
    "print(\"Phishing\" if y_pred[0] == 1 else \"Legitimate\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
